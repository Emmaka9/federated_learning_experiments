{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emmaka9/federated_learning_experiments/blob/main/flower_with_paillier_enc/fl_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHaLmdO_NEA"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7GOtLfq6bHO",
        "outputId": "d178aad8-3ac2-4c6f-f753-3e898dbb6553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Collecting flwr[simulation]\n",
            "  Downloading flwr-1.8.0-py3-none-any.whl (330 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography<43.0.0,>=42.0.4 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (42.0.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.62.2)\n",
            "Collecting iterators<0.0.3,>=0.0.2 (from flwr[simulation])\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.25.2)\n",
            "Collecting protobuf<5.0.0,>=4.25.2 (from flwr[simulation])\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome<4.0.0,>=3.18.0 (from flwr[simulation])\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (2.0.1)\n",
            "Requirement already satisfied: typer[all]<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (0.9.4)\n",
            "Collecting pydantic<2.0.0 (from flwr[simulation])\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray==2.6.3 (from flwr[simulation])\n",
            "  Downloading ray-2.6.3-cp310-cp310-manylinux2014_x86_64.whl (56.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (3.13.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (24.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.6.3->flwr[simulation]) (2.31.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43.0.0,>=42.0.4->flwr[simulation]) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->flwr[simulation]) (4.11.0)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<0.10.0,>=0.9.0->flwr[simulation])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<0.10.0,>=0.9.0->flwr[simulation])\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (13.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (2.16.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.6.3->flwr[simulation]) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.6.3->flwr[simulation]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.6.3->flwr[simulation]) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.6.3->flwr[simulation]) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.6.3->flwr[simulation]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.6.3->flwr[simulation]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.6.3->flwr[simulation]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.6.3->flwr[simulation]) (2024.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.1.2)\n",
            "Installing collected packages: shellingham, pydantic, pycryptodome, protobuf, iterators, colorama, ray, flwr\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.0\n",
            "    Uninstalling pydantic-2.7.0:\n",
            "      Successfully uninstalled pydantic-2.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 flwr-1.8.0 iterators-0.0.2 protobuf-4.25.3 pycryptodome-3.20.0 pydantic-1.10.15 ray-2.6.3 shellingham-1.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install protobuf==3.20.3\n",
        "!pip install -U flwr[\"simulation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUYu55ThT2Jk",
        "outputId": "b83ba751-32c1-4efd-c159-365c4e7b929e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phe\n",
            "  Downloading phe-1.5.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m728.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: phe\n",
            "Successfully installed phe-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install phe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TOb4ZusFCuy"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilgZO-PDFCgO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python.__version__"
      ],
      "metadata": {
        "id": "AmZJ9pK5RJkb",
        "outputId": "1ae12dae-ac65-47e5-c7d3-b25baa2aa984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: python.__version__: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42xVTi2ORJaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdYCBrmuVzUf"
      },
      "outputs": [],
      "source": [
        "from phe import paillier\n",
        "import numpy as np\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# DEVICE = (\n",
        "#         \"cuda\"\n",
        "# if torch.cuda.is_available()\n",
        "# else \"mps\"\n",
        "# if torch.backends.mps.is_available()\n",
        "# else \"cpu\"\n",
        "# )\n",
        "DEVICE = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkiLYkf9esZB"
      },
      "source": [
        "### Set up Paillier Enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKoslucYV1Iu",
        "outputId": "ad42c443-90f0-4c9f-a77e-f698fbb1b1d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def generate_keys():\n",
        "    public_key, private_key = paillier.generate_paillier_keypair()\n",
        "    return public_key, private_key\n",
        "\n",
        "def encrypt_vector(public_key, array):\n",
        "    print(\"=========Encrypting==========\")\n",
        "    flat_array = array.flatten()\n",
        "    encrypted_flat_array = [public_key.encrypt(float(i)).ciphertext() for i in flat_array]\n",
        "    encrypted_array = np.array(encrypted_flat_array).reshape(array.shape)\n",
        "    return encrypted_array\n",
        "\n",
        "\n",
        "\n",
        "def decrypt_vector(private_key, vector):\n",
        "    return np.array([private_key.decrypt(v) for v in vector])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgRqqjWcb-gf"
      },
      "outputs": [],
      "source": [
        "# Generate Paillier Keys\n",
        "encryptor, decryptor = generate_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbtn9eJ2ecQi",
        "outputId": "04805bea-92a1-4091-be59-6512473cba6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PaillierPublicKey 9367df9426>,\n",
              " <PaillierPrivateKey for <PaillierPublicKey 9367df9426>>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "encryptor, decryptor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp_8mTEieyyi"
      },
      "source": [
        "### A simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrM3HdT7e5OA"
      },
      "outputs": [],
      "source": [
        "# define a simple model\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.linear = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "model = SimpleModel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgoieH_DFUex"
      },
      "source": [
        "### Data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdDL_bW_FT-N"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_data(samples = 100):\n",
        "    X = np.random.randn(samples, 10).astype(np.float32) # 10 features\n",
        "    y = (np.sum(X, axis=1)) + np.random.randn(samples).astype(np.float32) # sum of features + noise\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLncmzRZFjr9"
      },
      "source": [
        "### Training and Evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8v17lqTFjMu"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, epochs):\n",
        "\n",
        "    # certain types of layers that have different behavior during training vs testing (eval) such as dropout, batch_normalization layers\n",
        "    model.train() # set the model to training mode\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # training loop\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in train_loader: # an iterable that provides batches of data. Each iteration yields a batch of inputs(x) and y.\n",
        "            # reset the grads of all model params before loss calc.\n",
        "            optimizer.zero_grad() # gradients are accumulated in buffers whenever .backward() is called.\n",
        "            output = model(x) # forward computation defined in models forward function\n",
        "            # .view(-1,1) reshape y to ensure it has the correct shape for the loss func. Converts y it to column vector.\n",
        "            loss = criterion(output, y.view(-1, 1))\n",
        "            # computes gradient of the loss wrt all model parameters (or any tensor with requires_grad=True)\n",
        "\n",
        "            loss.backward() # optimizer in the next step will use these gradients to update the parameters.\n",
        "            optimizer.step() # updates the model params. update rule - sgd, adam, ...\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval() # eval mode\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            output = model(x)\n",
        "            loss = criterion(output, y.view(-1, 1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion):\n",
        "    return validate(model, test_loader, criterion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vi7t0AE_UYw"
      },
      "source": [
        "### Flower Client and Server setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU0_nMAKn-2m"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# Define flwr client\n",
        "\n",
        "class Client(fl.client.NumPyClient):\n",
        "    def __init__(self, model, train_loader, val_loader, test_loader):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "\n",
        "    def get_parameters(self, config) -> List[np.ndarray]:\n",
        "        # retrieve the current state of the model's params from the client's local mdoel.\n",
        "        '''\n",
        "        1. extract params\n",
        "        2. convert params from tensors to numpy arrays. Flwr operates with numpy arrays for parameter exchange\n",
        "        to ensure framework agnosticism and to facilitate serialization\n",
        "        3. return params - returns a list of numpy arrays, where each array correspond to params of a particular layer or part\n",
        "        of the model\n",
        "\n",
        "        Process:\n",
        "        -> model.state_dict() - state_dict of a pytorch model is a python dict that maps each layer to its parameter tensor.\n",
        "        state_dict().items() - returns a list of key-val pairs where keys are strings representing the names of the layers, and\n",
        "        values are the parameters' tensors of those layers.\n",
        "        -> val.cpu() move the val tensor to the cpu if it isn't already there. Tensors on GPU cannot be directly converted to\n",
        "        numpy arrays, and operations involving numpy arrays typically require tensors to be on CPU.\n",
        "        -> .numpy() converts pytorch tensors to numpy arrs. used for param serialization and are easy to handle across different\n",
        "        computing environments.\n",
        "        '''\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters: List[np.ndarray]) -> None:\n",
        "        # update the local model with parameters received from the server\n",
        "        # arg - params: parameter from the global model\n",
        "        '''\n",
        "        In this step, the aggregated updates from multiple clients are distributed back to each client\n",
        "        1. receive params - takes a list of numpy arrays as input\n",
        "        2. Update model - convert numpy arrays back to pytorch tensors and ensure each param tensor in the model\n",
        "        is updated accordingly\n",
        "        3. Synchronization - the update syncs the local model with the global model state as maintained by the server.\n",
        "        '''\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters) # tuples: each tuple contains a parameter name and corresponding\n",
        "        # new parameter value (as a numpy arr)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict}) # new state dict\n",
        "        self.model.load_state_dict(state_dict, strict = True) # update the model params with the new_state_dict. strict=True ensures\n",
        "        # the keys in the state_dict match exactly with the keys in the model's current state_dict.\n",
        "\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        '''\n",
        "        '''\n",
        "        self.set_parameters(parameters)\n",
        "        loss = train(self.model, self.train_loader, self.criterion, self.optimizer, epochs=1)\n",
        "        updated_params = self.get_parameters(self.model)\n",
        "        encrypted_params = [encrypt_vector(encryptor, p) for p in updated_params]\n",
        "        return updated_params, len(self.train_loader), {'loss' : loss}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        loss = validate(self.model, self.val_loader, self.criterion)\n",
        "        return loss, len(self.val_loader), {'loss': loss}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNvVdImGTxHw"
      },
      "source": [
        "### Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyTGVV1vofAW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaeLSocZhk2t"
      },
      "source": [
        "### Client Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMeaJwoR_lPY"
      },
      "source": [
        "\n",
        "Having 10 clients would mean having 10 instances of FlowerClient in memory.\n",
        "Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients\n",
        "participates in a single round of federated learning.\n",
        "\n",
        "In addition to the regular capabilities where server and clients run on multiple machines, Flower, therefore,\n",
        "provides special simulation capabilities that create FlowerClient instances only when they are actually necessary for\n",
        "training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function\n",
        "called client_fn that creates a FlowerClient instance on demand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p21qVl9JL5C"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8S7rxb4homk"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> fl.client.Client:\n",
        "    # Create a flwr client representing a single organization\n",
        "\n",
        "\n",
        "    # load model\n",
        "    model = SimpleModel().to(DEVICE)\n",
        "\n",
        "    # Load data\n",
        "    # each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    X_train, y_train = generate_data(1000)\n",
        "    X_val, y_val = generate_data(200)\n",
        "    X_test, y_test = generate_data(200)\n",
        "\n",
        "    train_loader = [(torch.tensor(X_train[i : i+32]), torch.tensor(y_train[i : i+32])) for i in range(0, len(y_train), 32)]\n",
        "    val_loader = [(torch.tensor(X_val[i : i+32]), torch.tensor(y_val[i : i+32])) for i in range(0, len(y_val), 32)]\n",
        "    test_loader = [(torch.tensor(X_test[i : i+32]), torch.tensor(y_test[i : i+32])) for i in range(0, len(y_test), 32)]\n",
        "\n",
        "    # create a single flwr client representing a single org\n",
        "    return Client(model, train_loader, val_loader, test_loader).to_client()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0fHK9utEaZS"
      },
      "source": [
        "client_fn which allows Flower to create FlowerClient instances whenever it needs to call fit or evaluate on one particular client."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "#     # Multiply accuracy of each client by number of examples used\n",
        "#     accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "#     examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "#     # Aggregate and return custom metric (weighted average)\n",
        "#     return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "0DY8HiNA0p-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWFwOP_ZESda",
        "outputId": "4ccf5ac1-4220-41c7-cb36-53f2a30f055b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
            "INFO:flwr:Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-04-22 17:44:14,977\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'object_store_memory': 3954586828.0, 'memory': 7909173659.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'object_store_memory': 3954586828.0, 'memory': 7909173659.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=8341)\u001b[0m 2024-04-22 17:44:24.987468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8341)\u001b[0m 2024-04-22 17:44:24.987543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8341)\u001b[0m 2024-04-22 17:44:24.990054: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8341)\u001b[0m 2024-04-22 17:44:27.261131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "INFO:flwr:Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "INFO:flwr:[ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\u001b[2m\u001b[36m(pid=8340)\u001b[0m 2024-04-22 17:44:24.988269: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8340)\u001b[0m 2024-04-22 17:44:24.988319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8340)\u001b[0m 2024-04-22 17:44:24.990643: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8340)\u001b[0m 2024-04-22 17:44:27.260121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "INFO:flwr:[ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "INFO:flwr:[ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "INFO:flwr:[ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8340)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "INFO:flwr:[ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=8341)\u001b[0m =========Encrypting==========\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "INFO:flwr:[SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 rounds in 321.74s\n",
            "INFO:flwr:Run finished 5 rounds in 321.74s\n",
            "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
            "INFO:flwr:History (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 5.581869731630598\\n'\n",
            "INFO:flwr:\t('\\tround 1: 5.581869731630598\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 3.3346040521349227\\n'\n",
            "INFO:flwr:\t '\\tround 2: 3.3346040521349227\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 2.1632581421307155\\n'\n",
            "INFO:flwr:\t '\\tround 3: 2.1632581421307155\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 1.6629564217158725\\n'\n",
            "INFO:flwr:\t '\\tround 4: 1.6629564217158725\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 1.3776521563529969\\n')\n",
            "INFO:flwr:\t '\\tround 5: 1.3776521563529969\\n')\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "('\\tround 1: 5.581869731630598\\n'\n",
              " '\\tround 2: 3.3346040521349227\\n'\n",
              " '\\tround 3: 2.1632581421307155\\n'\n",
              " '\\tround 4: 1.6629564217158725\\n'\n",
              " '\\tround 5: 1.3776521563529969\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# create fedavg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit = 1.0, # sample 100% of available clients for training\n",
        "    fraction_evaluate=0.5, # sample 50% of avaliable clients for evaluation\n",
        "    min_fit_clients=10, # never sample less than 10 clients for training\n",
        "    min_evaluate_clients=5, #never sample less than 5 clients for eval\n",
        "    min_available_clients=10, # wait until all 10 clients are available\n",
        "    #evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        "\n",
        ")\n",
        "\n",
        "# Specify the rosources each of your clients used. By default, each client will be allocated 1x cpu and 0x gpus\n",
        "client_resources = {'num_cpus': 1, 'num_gpus': 0.0}\n",
        "if DEVICE.type =='cuda':\n",
        "    # here we are assigning an entire gpu for each client.\n",
        "    client_resources = {'num_cpus': 1, 'num_gpus': 1.0}\n",
        "    # see documentation for details\n",
        "\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=10,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd4jXgUkvzZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c62c26-945a-4181-a9c3-d29013e18eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sp_8mTEieyyi",
        "WgoieH_DFUex"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNfgnlOpcI15gR79y5mm2vp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}